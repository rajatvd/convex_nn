{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "750474ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train neural networks on a synthetic classification dataset using convex optimization.\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6284d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "from convex_nn.private.utils.data import gen_classification_data\n",
    "\n",
    "from convex_nn.optimize import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf47351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realizable synthetic classification problem (ie. Figure 1)\n",
    "n_train = 1000\n",
    "n_test = 1000\n",
    "d = 25\n",
    "hidden_units = 100\n",
    "kappa = 10  # condition number\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = gen_classification_data(123, n_train, n_test, d, hidden_units, kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0dfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, y):\n",
    "    return np.sum((np.sign(logits) == y)) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd5ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast data\n",
    "tX_train, ty_train, tX_test, ty_test = [torch.tensor(z, dtype=torch.float) for z in [X_train, y_train, X_test, y_test]]\n",
    "\n",
    "loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(tX_train, ty_train), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7897edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1000\n",
    "tol = 1e-6    \n",
    "lam = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a9d70d",
   "metadata": {},
   "source": [
    "## Non-Convex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "714b25d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.433\n",
      "0/1000: Obj - 0.17481637001037598, Grad - 0.35416796803474426\n",
      "25/1000: Obj - 0.11591842770576477, Grad - 0.00950573105365038\n",
      "50/1000: Obj - 0.10122910141944885, Grad - 0.01757941208779812\n",
      "75/1000: Obj - 0.09057214111089706, Grad - 0.04705703258514404\n",
      "100/1000: Obj - 0.08221948146820068, Grad - 0.026237286627292633\n",
      "125/1000: Obj - 0.07646583765745163, Grad - 0.041473351418972015\n",
      "150/1000: Obj - 0.07053500413894653, Grad - 0.0018400861881673336\n",
      "175/1000: Obj - 0.06606698781251907, Grad - 0.012897776439785957\n",
      "200/1000: Obj - 0.0616372786462307, Grad - 0.001382817281410098\n",
      "225/1000: Obj - 0.05873275548219681, Grad - 0.026050196960568428\n",
      "250/1000: Obj - 0.05530163645744324, Grad - 0.02188556082546711\n",
      "275/1000: Obj - 0.051780033856630325, Grad - 0.0015152401756495237\n",
      "300/1000: Obj - 0.04925689473748207, Grad - 0.004436086397618055\n",
      "325/1000: Obj - 0.04647251218557358, Grad - 0.0015814988873898983\n",
      "350/1000: Obj - 0.044255148619413376, Grad - 0.002444556448608637\n",
      "375/1000: Obj - 0.04221384972333908, Grad - 0.0062861451879143715\n",
      "400/1000: Obj - 0.040334008634090424, Grad - 0.0060160462744534016\n",
      "425/1000: Obj - 0.038873475044965744, Grad - 0.014222453348338604\n",
      "450/1000: Obj - 0.03717980533838272, Grad - 0.011175471358001232\n",
      "475/1000: Obj - 0.0355483740568161, Grad - 0.0034653048496693373\n",
      "500/1000: Obj - 0.034658290445804596, Grad - 0.01254439726471901\n",
      "525/1000: Obj - 0.03342602401971817, Grad - 0.014778291806578636\n",
      "550/1000: Obj - 0.03211788088083267, Grad - 0.0031806500628590584\n",
      "575/1000: Obj - 0.03129938989877701, Grad - 0.007755479775369167\n",
      "600/1000: Obj - 0.030346408486366272, Grad - 0.004206682555377483\n",
      "625/1000: Obj - 0.029698986560106277, Grad - 0.007533086463809013\n",
      "650/1000: Obj - 0.02884759195148945, Grad - 0.004295671824365854\n",
      "675/1000: Obj - 0.02834351733326912, Grad - 0.010861196555197239\n",
      "700/1000: Obj - 0.027557259425520897, Grad - 0.004554396495223045\n",
      "725/1000: Obj - 0.026930252090096474, Grad - 0.0027971728704869747\n",
      "750/1000: Obj - 0.026503553614020348, Grad - 0.004564890172332525\n",
      "775/1000: Obj - 0.026022693142294884, Grad - 0.005971753969788551\n",
      "800/1000: Obj - 0.025383496657013893, Grad - 0.0014678342267870903\n",
      "825/1000: Obj - 0.025051221251487732, Grad - 0.004164862912148237\n",
      "850/1000: Obj - 0.02460704743862152, Grad - 0.0033996885176748037\n",
      "875/1000: Obj - 0.024208014830946922, Grad - 0.0040012747049331665\n",
      "900/1000: Obj - 0.023860717192292213, Grad - 0.004817785229533911\n",
      "925/1000: Obj - 0.02353018708527088, Grad - 0.005260096862912178\n",
      "950/1000: Obj - 0.02321411855518818, Grad - 0.00474228709936142\n",
      "975/1000: Obj - 0.022911682724952698, Grad - 0.004567313939332962\n",
      "Test Accuracy: 0.942\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "\n",
    "# create model\n",
    "nc_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=d, out_features=hidden_units, bias=False), \n",
    "    torch.nn.ReLU(), \n",
    "    torch.nn.Linear(in_features=hidden_units, out_features=1, bias=False))\n",
    "\n",
    "# Acc Before Training\n",
    "print(\"Test Accuracy:\", accuracy(nc_model(tX_test).detach().numpy(), y_test))\n",
    "\n",
    "sgd = torch.optim.SGD(nc_model.parameters(), lr=lr)\n",
    "\n",
    "for i in range(max_epochs):\n",
    "    for X, y in loader:\n",
    "        nc_model.zero_grad()\n",
    "        l2_penalty = sum([torch.sum(param ** 2) for param in nc_model.parameters()])\n",
    "        obj = torch.sum((nc_model(X) - y) ** 2) / (2 * len(y)) + lam * l2_penalty\n",
    "        obj.backward()\n",
    "        \n",
    "        sgd.step()\n",
    "\n",
    "    # check for convergence\n",
    "    \n",
    "    nc_model.zero_grad()\n",
    "    l2_penalty = sum([torch.sum(param ** 2) for param in nc_model.parameters()])\n",
    "    obj = torch.sum((nc_model(tX_train) - ty_train) ** 2) / (2 * len(y_train)) + lam * l2_penalty\n",
    "    obj.backward()    \n",
    "    grad_norm = sum([torch.sum(param.grad ** 2) for param in nc_model.parameters()])\n",
    "\n",
    "    if grad_norm <= tol:\n",
    "        print(f\"Converged at {i}/{max_epochs}\")\n",
    "        break\n",
    "\n",
    "    if i % 25 == 0:\n",
    "        print(f\"{i}/{max_epochs}: Obj - {obj}, Grad - {grad_norm}\")\n",
    "\n",
    "# Acc After Training\n",
    "print(\"Test Accuracy:\", accuracy(nc_model(tX_test).detach().numpy(), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c20ec14f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:convex_nn:Pre-Optimization Metrics: Train Set objective: 0.5, Train Set grad_norm: 0.1562219113111496, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7577f0d744d472c81b233f61eaa70a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fista:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set objective: 0.5, Train Set grad_norm: 0.1562219113111496, \n",
      "Train Set objective: 0.1280835418701172, Train Set grad_norm: 1.120530032494571e-05, \n",
      "Train Set objective: 0.12403209686279297, Train Set grad_norm: 2.0719967324112076e-06, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:convex_nn:Termination criterion satisfied at iteration 67/10000. Exiting optimization loop.\n",
      "INFO:convex_nn:Post-Optimization Metrics: Train Set objective: 0.12256829071044922, Train Set grad_norm: 8.999828082778549e-07, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\n",
      "Test Accuracy: 0.954\n",
      "Hidden Layer Size: 418\n"
     ]
    }
   ],
   "source": [
    "# number of activation patterns to use.\n",
    "max_neurons = 1000\n",
    "\n",
    "# train model\n",
    "cvx_model, metrics = optimize(\"gated_relu\", \n",
    "                          max_neurons, ''\n",
    "                          lam, \n",
    "                          X_train, \n",
    "                          y_train, \n",
    "                          X_test, \n",
    "                          y_test, \n",
    "                          verbose=True,  \n",
    "                          device=\"cpu\")\n",
    "\n",
    "# Acc After Training\n",
    "print(\"\\n \\n\")\n",
    "print(\"Test Accuracy:\", accuracy(cvx_model(X_test), y_test))\n",
    "print(f\"Hidden Layer Size: {cvx_model.parameters[0].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1456e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
